---
title: BERT
id: 20210823182825
type: algorithme
tags:
  - algorithme
  - Google
  - Classement
  - référencement
  - 2019
  - Modèle de langage
---

Algorithme de [[20210807185404]] Google mis en place en 2019 dont le nom signifie  "Bidirectional Encoder Representations from Transformers", est un modèle de langage  qui utilise des techniques d'apprentissage en profondeur pour comprendre le contexte des mots dans un texte. 

## Caractéristiques clés

- **Compréhension bidirectionnelle** : Contrairement à d'autres modèles qui analysent les textes de gauche à droite ou de droite à gauche, BERT est capable de comprendre le contexte des mots dans les deux directions, ce qui lui permet de comprendre plus précisément le sens des mots en fonction de leur contexte.

- **Transformers** : BERT utilise les Transformers, qui sont des modèles basés sur l'attention qui peuvent prendre en compte l'ensemble du contexte d'un mot, et pas seulement son voisinage immédiat.

- **Pré-entraînement et fine-tuning** : BERT est pré-entraîné sur un grand corpus de texte non annoté (comme le corpus de livres de Google) puis affiné pour des tâches spécifiques, comme la compréhension de texte ou la classification de texte.

## Impact 

BERT a révolutionné le domaine du traitement du langage naturel et a permis d'améliorer significativement la performance des systèmes de recherche et de réponse aux questions, en fournissant des résultats plus précis et pertinents.

